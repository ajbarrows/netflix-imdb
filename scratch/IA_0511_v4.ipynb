{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_live():\n",
    "    ''' Load Netflix data set from disk. Load IMDb data sets from IMDb website. Merge on title, write merged\n",
    "    version to disk.'''\n",
    "    imdb_names = pd.read_csv(\"https://datasets.imdbws.com/title.basics.tsv.gz\", compression='gzip', delimiter = \"\\t\",\n",
    "                            low_memory = False)\n",
    "    imdb_ratings = pd.read_csv(\"https://datasets.imdbws.com/title.ratings.tsv.gz\", compression = 'gzip', delimiter = \"\\t\",\n",
    "                              low_memory = False)\n",
    "\n",
    "    # just need the unique id 'tconst'\n",
    "    imdb_names = imdb_names[['tconst', 'originalTitle']]\n",
    "    imdb = imdb_ratings.merge(imdb_names, how = 'left', on = 'tconst')\n",
    "\n",
    "    nflix = nflix.merge(imdb, how = 'left', left_on = 'title', right_on = 'originalTitle')\n",
    "    nflix.to_csv(\"data/nflix_merged.csv\")\n",
    "    \n",
    "    return nflix\n",
    "\n",
    "# only pull from by API if not on disk\n",
    "try:\n",
    "#    print('problem')\n",
    "    nflix = pd.read_csv(\"../data/nflix_sub.csv\")\n",
    "except:\n",
    "    nflix = load_data_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_year</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['3%']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['3%']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "      <td>21771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['7:19']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['23:59']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6</td>\n",
       "      <td>849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['9']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22408</th>\n",
       "      <td>22408</td>\n",
       "      <td>['Zubaan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22409</th>\n",
       "      <td>22409</td>\n",
       "      <td>['Zubaan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22410</th>\n",
       "      <td>22410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22411</th>\n",
       "      <td>22411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22412</th>\n",
       "      <td>22412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22413 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       title director cast    country  date_added rating  \\\n",
       "0               0      ['3%']      NaN  NaN     Brazil         NaN  TV-MA   \n",
       "1               1      ['3%']      NaN  NaN     Brazil         NaN  TV-MA   \n",
       "2               2    ['7:19']      NaN  NaN     Mexico         NaN  TV-MA   \n",
       "3               3   ['23:59']      NaN  NaN  Singapore         NaN      R   \n",
       "4               4       ['9']      NaN  NaN        NaN         NaN  PG-13   \n",
       "...           ...         ...      ...  ...        ...         ...    ...   \n",
       "22408       22408  ['Zubaan']      NaN  NaN      India         NaN  TV-14   \n",
       "22409       22409  ['Zubaan']      NaN  NaN      India         NaN  TV-14   \n",
       "22410       22410         NaN      NaN  NaN        NaN         NaN  TV-MA   \n",
       "22411       22411         NaN      NaN  NaN  Australia         NaN  TV-PG   \n",
       "22412       22412         NaN      NaN  NaN        NaN         NaN  TV-MA   \n",
       "\n",
       "       release_year  duration  description  averageRating  numVotes  \n",
       "0              2020       NaN          NaN            7.8    2053.0  \n",
       "1              2020       NaN          NaN            7.4   21771.0  \n",
       "2              2016       NaN          NaN            6.0     567.0  \n",
       "3              2011       NaN          NaN            4.6     849.0  \n",
       "4              2009       NaN          NaN            6.0      73.0  \n",
       "...             ...       ...          ...            ...       ...  \n",
       "22408          2015       NaN          NaN            6.1     389.0  \n",
       "22409          2015       NaN          NaN            7.3      10.0  \n",
       "22410          2019       NaN          NaN            NaN       NaN  \n",
       "22411          2019       NaN          NaN            6.9    1864.0  \n",
       "22412          2019       NaN          NaN            NaN       NaN  \n",
       "\n",
       "[22413 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nflix = nflix.replace(['None', 'Not Reported', 'not reported', '', ' ', 'NaN'], np.nan, regex=True)\n",
    "nflix.fillna(value=pd.np.nan, inplace=True)\n",
    "\n",
    "nflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22413 entries, 0 to 22412\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     22413 non-null  int64  \n",
      " 1   title          8314 non-null   object \n",
      " 2   director       277 non-null    object \n",
      " 3   cast           22 non-null     object \n",
      " 4   country        7429 non-null   object \n",
      " 5   date_added     0 non-null      float64\n",
      " 6   rating         22406 non-null  object \n",
      " 7   release_year   22413 non-null  int64  \n",
      " 8   duration       0 non-null      float64\n",
      " 9   description    0 non-null      float64\n",
      " 10  averageRating  20304 non-null  float64\n",
      " 11  numVotes       20304 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "nflix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nflix = nflix[nflix['averageRating'].isna() == False] \n",
    "\n",
    "y = nflix['averageRating'].values.ravel()\n",
    "X = nflix.drop(columns=['averageRating','director', 'cast', 'duration', 'description', 'date_added', 'Unnamed: 0'])\n",
    "\n",
    "#print('Here!', nflix['averageRating'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 0\n",
      "country 0\n",
      "rating 0\n",
      "release_year 0\n",
      "numVotes 0\n",
      "new shape: (20304, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20304 entries, 0 to 22411\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   title         20304 non-null  int64\n",
      " 1   country       20304 non-null  int64\n",
      " 2   rating        20304 non-null  int64\n",
      " 3   release_year  20304 non-null  int64\n",
      " 4   numVotes      20304 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sepdata(nonan_imp):\n",
    "    '''separates numerical and categorical variables into subsets\n",
    "    quant and qual'''    \n",
    "    for name in nonan_imp.columns:\n",
    "        if type(nonan_imp[name][1]) == str:\n",
    "            nonan_imp[name] = nonan_imp[name].astype(str)\n",
    "        elif type(nonan_imp[name][1]) == int:\n",
    "            #print(name)\n",
    "            nonan_imp[name] = nonan_imp[name].astype(int)\n",
    "        else:\n",
    "            #nonan_imp[name] = pd.to_numeric(nonan_imp[name])\n",
    "            nonan_imp[name] = nonan_imp[name].astype(str)\n",
    "\n",
    "    quant = nonan_imp.select_dtypes(['number', 'float', 'int'])\n",
    "    #print(quant.head)\n",
    "    qual = nonan_imp.select_dtypes(['object'])\n",
    "    #print(qual.head)\n",
    "    return quant, qual\n",
    "\n",
    "def prep():\n",
    "    ''' produces a clean dataframe of X predictors and the y response \n",
    "    also encodes categorical variables'''\n",
    "    fulldf = X\n",
    "    ''' cut needs to be value between 0 and 1'''\n",
    "    #nonan = dropcolna(fulldf, cut*len(fulldf))\n",
    "    #nonan_imp = impute(nonan, 'most_frequent') #can use median here    \n",
    "    quant, qual = sepdata(X)    \n",
    "    #nona_enc = nonan_imp\n",
    "    X_enc = X\n",
    "\n",
    "    '''\n",
    "    encoding catergorical variables\n",
    "    '''    \n",
    "    le = LabelEncoder()\n",
    "    X_enc[qual.columns] = X_enc[qual.columns].apply(lambda\n",
    "                col:le.fit_transform(col))    \n",
    "#    print(nona_enc.head)    \n",
    "\n",
    "    #y = y.values.ravel()\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "quant, qual = sepdata(X)\n",
    "X = prep()\n",
    "#y = y.values.ravel()\n",
    "\n",
    "\n",
    "\n",
    "def dropcolna(nonan):\n",
    "    ''' takes full dataframe and drops columns with more missingness\n",
    "    than the number, num, established by the cutoff later'''\n",
    "    \n",
    "    for feat in nonan.columns:\n",
    "        if nonan[feat].isna().sum() > len(nonan):\n",
    "            nonan.drop([feat], axis=1, inplace=True)\n",
    "        else:\n",
    "            '''sanity check for remaining nan'''\n",
    "            print(feat, nonan[feat].isna().sum())\n",
    "            pass\n",
    "    print('new shape:', nonan.shape)\n",
    "    return nonan\n",
    "\n",
    "def impute(nonan):\n",
    "    ''' imputes missing data by specified strategy, used \n",
    "    most frequent in this project'''\n",
    "    values = nonan.values\n",
    "\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')    \n",
    "    transformed_X = imp.fit_transform(X)    \n",
    "    nonan_imp = pd.DataFrame(transformed_X, \n",
    "                             columns = [item for item in nonan.columns])\n",
    "#    nonan_imp['days_to_death'] = y\n",
    "    ''' sanity check to make sure there is no missingness left'''    \n",
    "    print(nonan_imp)    \n",
    "    for feat in nonan_imp:\n",
    "        print('Here!', feat, nonan_imp[feat].isna().sum())\n",
    "    return nonan_imp \n",
    "\n",
    "\n",
    "\n",
    "X = dropcolna(X)\n",
    "#X_imp = impute(X)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "'''Helper function for cross validation'''\n",
    "        \n",
    "def split_folds(k):\n",
    "    return KFold(n_splits=k, random_state=1, shuffle=True)\n",
    "\n",
    "'''Models available'''\n",
    "\n",
    "def lin_reg(X, y):\n",
    "    ''' linear regression on all predictors'''\n",
    "    model = {'name':'Linear',\n",
    "             'mod_type':LinearRegression().fit(X,y),\n",
    "             'color':'maroon'}\n",
    "    return model\n",
    "\n",
    "def lasso_reg(X, y, n):\n",
    "    ''' lasso regression on all predictors'''\n",
    "    model = {'name':'Lasso',\n",
    "             'mod_type':LassoCV(cv = split_folds(n)).fit(X,y),\n",
    "             'color':'royalblue'}\n",
    "    return model\n",
    "\n",
    "def ridge_reg(X, y, n):\n",
    "    ''' ridge regression on all predictors'''\n",
    "    model = {'name':'Ridge',\n",
    "             'mod_type':RidgeCV(cv = split_folds(n)).fit(X,y),\n",
    "             'color':'deepskyblue'}\n",
    "    return model\n",
    "\n",
    "def elastic_net(X, y, n):\n",
    "    ''' elastic net regression on all predictors'''\n",
    "    model = {'name':'Elastic Net',\n",
    "             'mod_type':ElasticNetCV(cv = split_folds(n)).fit(X,y),\n",
    "             'color':'indigo'}\n",
    "    return model    \n",
    "\n",
    "def kneighbors(X, y, search):\n",
    "    ''' k-nearest neighbors model using boosted tree features\n",
    "    (see run_models in oopmod.py)'''\n",
    "    if search == True:\n",
    "        param_grid = {'n_neighbors': [i for i in range(5,30)],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'leaf_size': [i for i in range(20,40)],\n",
    "              'p': [1, 2]}\n",
    "        best_mod = GridSearchCV(KNeighborsRegressor(), param_grid=param_grid,\n",
    "                                scoring='neg_mean_squared_error',cv=5,\n",
    "                                verbose=True, pre_dispatch='2*n_jobs', n_jobs=-1)\n",
    "        best_mod.fit(X,y)   \n",
    "        mod = best_mod.best_estimator_\n",
    "        print(best_mod.best_params_)\n",
    "    else: \n",
    "        mod = KNeighborsRegressor(algorithm= 'auto', leaf_size= 20,\n",
    "                                  n_neighbors= 28, p= 1, weights= 'distance')\n",
    "    model = {'name':'KNN',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'orchid'}\n",
    "    return model    \n",
    "    \n",
    "def tree_reg(X, y, search):\n",
    "    ''' decision tree regression model'''\n",
    "    if search == True:\n",
    "        param_grid = {'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'min_samples_split': [0.001, 0.01, 0.1, 0.15],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'min_impurity_decrease': [0.0, 0.001, 0.01, 0.1]}\n",
    "        best_mod = GridSearchCV(tree.DecisionTreeRegressor(),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='neg_mean_squared_error',cv=5,\n",
    "                                verbose=True, pre_dispatch='2*n_jobs', n_jobs=-1)\n",
    "        best_mod.fit(X,y)    \n",
    "        print(best_mod.best_params_)\n",
    "        mod = best_mod.best_estimator_\n",
    "    else:\n",
    "        mod = tree.DecisionTreeRegressor(criterion= 'mse', max_features= 'auto',\n",
    "                                         min_impurity_decrease= 0.0,\n",
    "                                         min_samples_split= 0.1,\n",
    "                                         splitter= 'random')\n",
    "    model = {'name':'Tree',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'olivedrab'}\n",
    "    return model\n",
    "\n",
    "def rand_for(X, y, search):\n",
    "    ''' random forest model'''    \n",
    "    if search == True:\n",
    "        param_grid = {'n_estimators':[100],\n",
    "                'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "              'min_samples_split': [0.001, 0.01, 0.1, 0.15],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'min_impurity_decrease': [0.0, 0.001, 0.01, 0.1]}\n",
    "        best_mod = GridSearchCV(RandomForestRegressor(),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='neg_mean_squared_error',cv=5,\n",
    "                                verbose=True, pre_dispatch='2*n_jobs', n_jobs=-1)\n",
    "        best_mod.fit(X,y)    \n",
    "        print(best_mod.best_params_)    \n",
    "        mod = best_mod.best_estimator_\n",
    "    else:\n",
    "        mod = RandomForestRegressor(criterion= 'friedman_mse',\n",
    "                                    max_features= 'auto',\n",
    "                                    min_impurity_decrease= 0.01,\n",
    "                                    min_samples_split= 0.001,\n",
    "                                    n_estimators= 100)\n",
    "    model = {'name':'Random Forest',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'limegreen'}\n",
    "    return model\n",
    "\n",
    "def boost_for(X, y, search):\n",
    "    '''gradient boosted forest model '''        \n",
    "    if search == True:\n",
    "        param_grid = {\n",
    "                'learning_rate': [0.05, 0.02, 0.1],\n",
    "              'min_impurity_decrease': [0.001, 0.01, 0.1]}\n",
    "        best_mod = GridSearchCV(GradientBoostingRegressor(),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='neg_mean_squared_error',cv=5,\n",
    "                                verbose=True, pre_dispatch='2*n_jobs', n_jobs=-1)\n",
    "        best_mod.fit(X,y)    \n",
    "        print(best_mod.best_params_)    \n",
    "        mod = best_mod.best_estimator_\n",
    "    else:\n",
    "        mod = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                        min_impurity_decrease = 0.01)\n",
    "    model = {'name':'Boosted Forest',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'forestgreen'}\n",
    "    return model\n",
    "\n",
    "def supp_vec_reg(X, y, search): \n",
    "    ''' support vector regression model using boosted tree features,\n",
    "    see run_models in oopmod.py'''\n",
    "    if search == True:\n",
    "        param_grid = {'kernel': ['linear', 'rbf']}\n",
    "        \n",
    "        best_mod = GridSearchCV(SVR(), param_grid=param_grid,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                cv=5, verbose=True, pre_dispatch='2*n_jobs',\n",
    "                                n_jobs=-1)\n",
    "        best_mod.fit(X,y)    \n",
    "        print(best_mod.best_params_)\n",
    "        mod = best_mod.best_estimator_\n",
    "    else:\n",
    "        mod = SVR(kernel = 'linear')\n",
    "    \n",
    "    model = {'name':'SVR',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'purple'}\n",
    "    return model\n",
    "\n",
    "def mlp(X, y, search):\n",
    "    ''' multilayer perceptron model using boosted tree features,\n",
    "    see run_models in oopmod.py'''    \n",
    "    if search == True:\n",
    "        param_grid = {'hidden_layer_sizes': [i for i in range(1,15)],\n",
    "                      'activation': ['relu'], #identity, logistic, tanh\n",
    "                      'solver': ['adam','sgd'],\n",
    "                      'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "                      'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "                      'alpha': [0.001, 0.01, 0.1],\n",
    "                      'max_iter': [1000]}\n",
    "        best_mod = GridSearchCV(MLPRegressor(), param_grid=param_grid, scoring='neg_mean_squared_error',\n",
    "                           cv=3, verbose=True, pre_dispatch='2*n_jobs', n_jobs=-1)\n",
    "        best_mod.fit(X,y)\n",
    "        print(best_mod.best_params_)\n",
    "        mod = best_mod.best_estimator_ \n",
    "    else:\n",
    "        mod = MLPRegressor(activation= 'relu', alpha= 0.1,\n",
    "                           hidden_layer_sizes= 4, learning_rate= 'adaptive',\n",
    "                           learning_rate_init= 0.001, max_iter= 3568,\n",
    "                           solver= 'lbfgs')\n",
    "    \n",
    "    model = {'name':'MLP',\n",
    "             'mod_type':mod.fit(X,y),\n",
    "             'color':'goldenrod'}\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#import os\n",
    "#print(os.getcwd())\n",
    "\n",
    "#os.chdir('/Users/alyxcleveland/Documents/Complex Systems/Bayes/Final Project')\n",
    "#print(os.getcwd())\n",
    "\n",
    "\n",
    "#from dataprep import cleandata, dropcolna, impute, sepdata, prep\n",
    "#from models import split_folds, lin_reg, lasso_reg, ridge_reg, elastic_net\n",
    "#from models import kneighbors, tree_reg, rand_for, boost_for, supp_vec_reg, mlp\n",
    "\n",
    "\n",
    "class learn:\n",
    "    '''learning class to gather statistics on all models'''\n",
    "    def __init__(self, model, X, y, k):\n",
    "        self.model = model['mod_type']\n",
    "        self.name = model['name']\n",
    "        self.color = model['color']\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "\n",
    "    def cross_val(self):\n",
    "        '''cross validation of train/test MSE and explained variance with\n",
    "        adjustable number of k folds'''\n",
    "        scores = cross_validate(self.model, self.X, self.y,\n",
    "                                cv=split_folds(self.k), \n",
    "                                scoring=('r2', 'neg_mean_squared_error', \n",
    "                                          'explained_variance'),\n",
    "                                return_train_score=True,\n",
    "                                n_jobs=-1)\n",
    "        self.test_r2 = np.mean(scores['test_r2'])\n",
    "        self.test_r2_sd = np.std(scores['test_r2'])\n",
    "        self.test_mse = np.mean(np.abs(scores['test_neg_mean_squared_error']))\n",
    "        self.test_mse_sd = np.std(scores['test_neg_mean_squared_error'])\n",
    "        self.test_expvar = np.mean(np.abs(scores['test_explained_variance']))\n",
    "        self.test_expvar_sd = np.std(np.abs(scores['test_explained_variance']))\n",
    "        self.score = self.model.score\n",
    "        \n",
    "        self.train_r2 = np.mean(scores['train_r2'])\n",
    "        self.train_r2_sd = np.std(scores['train_r2'])\n",
    "        self.train_mse = np.mean(np.abs(scores['train_neg_mean_squared_error']))\n",
    "        self.train_mse_sd = np.std(scores['train_neg_mean_squared_error'])\n",
    "        self.train_expvar = np.mean(np.abs(scores['train_explained_variance']))\n",
    "        self.train_expvar_sd = np.std(np.abs(scores['train_explained_variance']))\n",
    "        print(self.name, 'done cross-validating')\n",
    "        \n",
    "    def get_coef(self):\n",
    "        '''extracts names of coefficients for linear models to make\n",
    "        feature plots'''\n",
    "        if type(self.model.coef_[0]) == list:\n",
    "            coef = pd.Series(self.model.coef_[0], index = self.X.columns)       \n",
    "        else:\n",
    "            coef = pd.Series(self.model.coef_, index = self.X.columns)\n",
    "        \n",
    "        if self.name == 'Linear':        \n",
    "            imp_coef = coef[(coef < -1e11)].sort_values()\n",
    "        elif self.name == 'Lasso':\n",
    "            imp_coef = coef[(coef > 0.1) | (coef < -0.1)].sort_values()\n",
    "        else:\n",
    "            imp_coef = coef[(coef > 1) | (coef < -1)].sort_values()        \n",
    "        return imp_coef\n",
    "    \n",
    "    def get_imp(self):\n",
    "        ''' extracts names of important features for tree models'''\n",
    "        importances = pd.Series(self.model.feature_importances_,\n",
    "                                index=self.X.columns).sort_values()     \n",
    "        imp = importances[importances > 0.01]\n",
    "        return imp\n",
    "    \n",
    "    def plot_feat(self): \n",
    "        ''' makes bar plot for feature importances for linear and tree models'''\n",
    "        if self.name in ['Linear', 'Lasso', 'Ridge', 'Elastic Net']:\n",
    "            imp = self.get_coef()\n",
    "            self.coef = list(imp.index)\n",
    "        else:\n",
    "            imp = self.get_imp()\n",
    "        plt.rcParams.update({'font.size': 30, 'figure.figsize':(10, 20)})\n",
    "        plt.gcf().subplots_adjust(left=0.3)\n",
    "        imp.plot(kind = \"barh\", color=self.color)\n",
    "        plt.grid(color='gray', which='major', axis='y', linestyle='--', alpha=0.5)        \n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(self.name)\n",
    "        plt.savefig('{}_featimp.svg'.format(self.name))\n",
    "        plt.show()\n",
    "        \n",
    "def run_models(X, y, k):\n",
    "    ''' runs and collect cross validation statistics for all models\n",
    "    and returns list of models with statistics to be plotted '''\n",
    "    \n",
    "    # linear = learn(lin_reg(X, y), X, y, k)\n",
    "    # linear.cross_val()\n",
    "    # print(linear.get_coef())\n",
    "    lasso = learn(lasso_reg(X, y, k), X, y, k)\n",
    "    lasso.cross_val()\n",
    "    ridge = learn(ridge_reg(X, y, k), X, y, k)\n",
    "    ridge.cross_val()    \n",
    "    elasnet = learn(elastic_net(X, y, k), X, y, k)\n",
    "    elasnet.cross_val()        \n",
    "    tree = learn(tree_reg(X, y, search=False), X, y, k)\n",
    "    tree.cross_val()\n",
    "    randfor = learn(rand_for(X, y, search=False), X, y, k)\n",
    "    randfor.cross_val()\n",
    "    boostfor = learn(boost_for(X, y, search=False), X, y, k)\n",
    "    boostfor.cross_val()\n",
    "    \n",
    "    boostfor.feat = list(boostfor.get_imp().index)\n",
    "    X = X[[item for item in X.columns if item in boostfor.feat]] \n",
    "    \n",
    "    knn = learn(kneighbors(X, y, search=False), X, y, k)\n",
    "    knn.cross_val()    \n",
    "    svr = learn(supp_vec_reg(X, y, search=False), X, y, k)\n",
    "    svr.cross_val()\n",
    "    perc = learn(mlp(X, y, search=False), X, y, k)\n",
    "    perc.cross_val()\n",
    "    \n",
    "    #models = [lasso, ridge, elasnet, knn, tree, randfor, boostfor]\n",
    "    # models = [linear, lasso, ridge, elasnet, knn, tree, randfor, boostfor]\n",
    "    models = [lasso, ridge, elasnet, tree, randfor, boostfor, knn, svr, perc]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return models\n",
    "    \n",
    "def feat_plots(models):\n",
    "    '''plots feature importance for linear and tree models using the \n",
    "    plot_feat function of the learn class'''\n",
    "    mods = [mod for mod in models if mod.name not in ['KNN', 'SVR', 'MLP']]\n",
    "    for mod in mods:\n",
    "        mod.plot_feat()\n",
    "    \n",
    "def bias_var(models):\n",
    "    '''MSE and explained variance plot for all models'''\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    for mod in models:\n",
    "        ax.scatter(mod.test_mse, mod.test_expvar, marker='o',\n",
    "                    s=200, c=mod.color, alpha=0.7)\n",
    "        if mod.name in ['Ridge', 'Elastic Net']:\n",
    "            ax.annotate(mod.name, (mod.test_mse-1000, mod.test_expvar+0.003))\n",
    "        elif mod.name in ['Linear', 'KNN', 'Tree']:\n",
    "            ax.annotate(mod.name, (mod.test_mse+0.002, mod.test_expvar-0.01))\n",
    "        elif mod.name in ['MLP', 'SVR']:\n",
    "            ax.annotate(mod.name, (mod.test_mse-20000, mod.test_expvar-0.01))        \n",
    "        else:\n",
    "            ax.annotate(mod.name, (mod.test_mse, mod.test_expvar))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.xlabel('Mean Squared Error')\n",
    "    plt.ylabel('Explained Variance')\n",
    "#    plt.savefig('biasvariance.svg')\n",
    "    plt.show()\n",
    "    \n",
    "def tt_mse(models):\n",
    "    '''train mse vs test mse bar plot for all models'''\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    train_mse = [mod.train_mse for mod in models]\n",
    "    train_mse_sd = [mod.train_mse_sd for mod in models]\n",
    "\n",
    "    test_mse = [mod.test_mse for mod in models]\n",
    "    test_mse_sd = [mod.test_mse_sd for mod in models]\n",
    "    \n",
    "    ind = np.arange(len(models))\n",
    "    width = 0.35 \n",
    "    ax.bar(ind, train_mse, width,color=[mod.color for mod in models],\n",
    "                alpha=0.5, yerr=train_mse_sd)\n",
    "    ax.bar(ind + width, test_mse, width,\n",
    "                color=[mod.color for mod in models], yerr=test_mse_sd)\n",
    "    ax.set_title('Training & Testing MSE')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(['Linear', 'Lasso', 'Ridge', 'EN', 'KNN', 'Tree',\n",
    "                        'RF', 'BF', 'SVR', 'MLP'])\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "#    plt.savefig('tt_mse.svg')\n",
    "    plt.show()\n",
    "\n",
    "def tt_expvar(models):\n",
    "    '''train explained variance vs test explained variance bar plot\n",
    "    for all models'''\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    train_ev = [mod.train_expvar for mod in models]\n",
    "    train_ev_sd = [mod.train_expvar_sd for mod in models]\n",
    "\n",
    "    test_ev = [mod.test_expvar for mod in models]\n",
    "    test_ev_sd = [mod.test_expvar_sd for mod in models]\n",
    "    \n",
    "    ind = np.arange(len(models)) \n",
    "    width = 0.35 \n",
    "    ax.bar(ind, train_ev, width,color=[mod.color for mod in models],\n",
    "                alpha=0.5, yerr=train_ev_sd)\n",
    "    \n",
    "    ax.bar(ind + width, test_ev, width,\n",
    "                color=[mod.color for mod in models], yerr=test_ev_sd)\n",
    "    ax.set_title('Training & Testing Explained Variance')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(['Linear', 'Lasso', 'Ridge', 'EN', 'KNN', 'Tree',\n",
    "                        'RF', 'BF', 'SVR', 'MLP'])    \n",
    "    plt.ylabel('Explained Variance')\n",
    "#    plt.savefig('tt_ev.svg')\n",
    "    plt.show()    \n",
    "\n",
    "def main(X, y):\n",
    "    ''' main function provides prepared and encoded data to\n",
    "    run all models and produce plots'''\n",
    "    \n",
    "    \n",
    "    k=5\n",
    "    models = run_models(X, y, k)\n",
    "    \n",
    "    \n",
    "    #feat_plots(models)\n",
    "    bias_var(models)\n",
    "    tt_mse(models)\n",
    "    tt_expvar(models)\n",
    "\n",
    "# # X, y = prep(0.01, enc=True)\n",
    "\n",
    "# main(X, y)\n",
    "\n",
    "#main(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso done cross-validating\n",
      "Ridge done cross-validating\n",
      "Elastic Net done cross-validating\n",
      "Tree done cross-validating\n",
      "Random Forest done cross-validating\n",
      "Boosted Forest done cross-validating\n",
      "KNN done cross-validating\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)\n",
    "main(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
